{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_ybgqLyDJwh"
   },
   "outputs": [],
   "source": [
    "# #colabを使う方はこちらを使用ください。\n",
    "# !pip install torch==1.5.0\n",
    "# !pip install torchvision==0.6.0\n",
    "# !pip install torchtext==0.3.1\n",
    "# !pip install numpy==1.21.6\n",
    "# !pip install matplotlib==3.2.2\n",
    "# !pip install Pillow==7.1.2\n",
    "# !pip install opencv-python==4.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JSI-ob1LXJ3"
   },
   "outputs": [],
   "source": [
    "#執筆時点で存在するcolab固有のエラーを回避\n",
    "from PIL import Image\n",
    "def register_extension(id, extension): \n",
    "    Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "    for extension in extensions: \n",
    "        register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colabを使う方は以下セルのコメントアウトを解除して実行してください\n",
    "\n",
    "Google Driveにマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "VGlfMTUfa-It",
    "outputId": "face04d4-af74-44f8-ead0-edf0edf2ae75"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変更の必要がある場合はパスを変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GpXhG3lzbSBK",
    "outputId": "4a2073f5-ac8b-46ee-ee00-beaf86c321d8"
   },
   "outputs": [],
   "source": [
    "# cd /content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dLtNvfx7bSSj",
    "outputId": "34b4184b-9237-4df0-c73c-ec27e23bee5e"
   },
   "outputs": [],
   "source": [
    "# !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfdH0jXxC-pk"
   },
   "outputs": [],
   "source": [
    "# パッケージのインポート\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from net import weights_init, Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UAp9p1iOC-pp",
    "outputId": "c6c84d5b-4d45-4466-99e4-c64d0539115f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f370408a630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定\n",
    "workers = 2\n",
    "batch_size=50\n",
    "nz = 100\n",
    "nch_g = 64\n",
    "nch_d = 64\n",
    "n_epoch = 200\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './result_lsgan'\n",
    "display_interval = 100\n",
    "\n",
    "# 保存先ディレクトリを作成\n",
    "try:\n",
    "    os.makedirs(outf, exist_ok=True)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "# 乱数のシード（種）を固定\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uZLNaplkC-pt",
    "outputId": "dd0191ec-3987-432a-9e43-cdc519742763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# STL-10のトレーニングデータセットとテストデータセットを読み込む\n",
    "trainset = dset.STL10(\n",
    "    root='./dataset/stl10_root',\n",
    "    download=True,\n",
    "    split='train+unlabeled',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))   # ラベルを使用しないのでラベルなしを混在した'train+unlabeled'を読み込む\n",
    "\n",
    "testset = dset.STL10(\n",
    "    root='./dataset/stl10_root',\n",
    "    download=True,\n",
    "    split='test',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "\n",
    "dataset = trainset + testset    # STL-10のトレーニングデータセットとテストデータセットを合わせて訓練データとする\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=int(workers))\n",
    "\n",
    "# 学習に使用するデバイスを得る。可能ならGPUを使用する\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "vIJpbNtvC-pw",
    "outputId": "c6337409-9447-4cda-9fb7-7fa7a6d1997e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 生成器G。ランダムベクトルから贋作画像を生成する\n",
    "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
    "netG.apply(weights_init)    # weights_init関数で初期化\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "rriIYwAFC-pz",
    "outputId": "21951289-3831-490f-ad2f-55a266cca25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 識別器D。画像が、元画像か贋作画像かを識別する\n",
    "netD = Discriminator(nch_d=nch_d).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjfl5HxRC-p1"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
    "\n",
    "# オプティマイザ−のセットアップ\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  # 確認用の固定したノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2548
    },
    "colab_type": "code",
    "id": "lckGpHvMC-p5",
    "outputId": "44709856-a6de-4a38-99cb-407bed9b45f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200][1/2260] Loss_D: 3.741 Loss_G: 18.051 D(x): 0.302 D(G(z)): -0.523/5.165\n",
      "[1/200][101/2260] Loss_D: 20.945 Loss_G: 26.064 D(x): 0.277 D(G(z)): -4.417/6.065\n",
      "[1/200][201/2260] Loss_D: 0.717 Loss_G: 3.240 D(x): 1.152 D(G(z)): 0.708/-0.774\n",
      "[1/200][301/2260] Loss_D: 0.165 Loss_G: 1.134 D(x): 1.023 D(G(z)): 0.065/-0.045\n",
      "[1/200][401/2260] Loss_D: 0.221 Loss_G: 1.738 D(x): 1.114 D(G(z)): 0.253/-0.307\n",
      "[1/200][501/2260] Loss_D: 0.227 Loss_G: 1.130 D(x): 1.033 D(G(z)): 0.290/-0.048\n",
      "[1/200][601/2260] Loss_D: 0.209 Loss_G: 0.860 D(x): 1.047 D(G(z)): 0.265/0.096\n",
      "[1/200][701/2260] Loss_D: 0.180 Loss_G: 0.825 D(x): 0.831 D(G(z)): 0.160/0.108\n",
      "[1/200][801/2260] Loss_D: 0.221 Loss_G: 0.572 D(x): 0.709 D(G(z)): -0.087/0.270\n",
      "[1/200][901/2260] Loss_D: 0.205 Loss_G: 1.215 D(x): 1.013 D(G(z)): 0.333/-0.086\n",
      "[1/200][1001/2260] Loss_D: 0.103 Loss_G: 0.672 D(x): 0.780 D(G(z)): 0.028/0.194\n",
      "[1/200][1101/2260] Loss_D: 0.168 Loss_G: 1.408 D(x): 1.174 D(G(z)): 0.217/-0.179\n",
      "[1/200][1201/2260] Loss_D: 0.096 Loss_G: 1.286 D(x): 0.937 D(G(z)): 0.102/-0.119\n",
      "[1/200][1301/2260] Loss_D: 0.089 Loss_G: 1.154 D(x): 0.968 D(G(z)): 0.096/-0.063\n",
      "[1/200][1401/2260] Loss_D: 0.181 Loss_G: 0.572 D(x): 0.703 D(G(z)): 0.009/0.277\n",
      "[1/200][1501/2260] Loss_D: 0.124 Loss_G: 1.035 D(x): 0.867 D(G(z)): 0.210/-0.009\n",
      "[1/200][1601/2260] Loss_D: 0.345 Loss_G: 1.818 D(x): 1.163 D(G(z)): 0.438/-0.308\n",
      "[1/200][1701/2260] Loss_D: 0.271 Loss_G: 1.706 D(x): 1.224 D(G(z)): 0.333/-0.291\n",
      "[1/200][1801/2260] Loss_D: 0.097 Loss_G: 1.048 D(x): 0.916 D(G(z)): -0.006/-0.009\n",
      "[1/200][1901/2260] Loss_D: 0.175 Loss_G: 0.861 D(x): 0.784 D(G(z)): 0.145/0.084\n",
      "[1/200][2001/2260] Loss_D: 0.115 Loss_G: 0.806 D(x): 0.764 D(G(z)): 0.061/0.113\n",
      "[1/200][2101/2260] Loss_D: 0.172 Loss_G: 0.794 D(x): 0.821 D(G(z)): 0.126/0.133\n"
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        real_image = data[0].to(device)     # 元画像\n",
    "        sample_size = real_image.size(0)    # 画像枚数\n",
    "        noise = torch.randn(sample_size, nz, 1, 1, device=device)   # 正規分布からノイズを生成\n",
    "        \n",
    "        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n",
    "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        netD.zero_grad()    # 勾配の初期化\n",
    "\n",
    "        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n",
    "        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n",
    "        \n",
    "        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n",
    "        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
    "        errD.backward()    # 誤差逆伝播\n",
    "        optimizerD.step()   # Dのパラメーターを更新\n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        netG.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n",
    "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n",
    "        errG.backward()     # 誤差逆伝播\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step()   # Gのパラメータを更新\n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloader),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n",
    "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用画像の生成\n",
    "    ############################\n",
    "    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n",
    "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "                      normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # モデルの保存\n",
    "    ############################\n",
    "    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n",
    "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnVHkaZAR7bp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "section6_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "pytorch_handbook-cxE4JzpW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1627ff8c3f0278be0285d4bfdc18dde91f8374edbf4a554c43de70be81795e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
