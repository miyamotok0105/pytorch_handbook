{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #colabを使う方はこちらを使用ください。\n",
    "# !pip install torch==1.5.0\n",
    "# !pip install torchvision==0.6.0\n",
    "# !pip install torchtext==0.3.1\n",
    "# !pip install numpy==1.21.6\n",
    "# !pip install matplotlib==3.2.2\n",
    "# !pip install Pillow==7.1.2\n",
    "# !pip install opencv-python==4.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多対多のリカレントニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っていないデータにtorch.nn.LSTＭを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: torch.Size([8, 2])\n",
      "input sequence: torch.Size([6, 2])\n",
      "input sequence: torch.Size([10, 2])\n",
      "output sequence: torch.Size([8, 4])\n",
      "output sequence: torch.Size([6, 4])\n",
      "output sequence: torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "seq_len_list = [8, 6, 10]\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = []\n",
    "for seq_len in seq_len_list:\n",
    "    iseq = torch.randn(seq_len, input_size)\n",
    "    print('input sequence:', iseq.shape)\n",
    "    input_seq.append(iseq)\n",
    "\n",
    "# ネットワークの定義\n",
    "net = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "\n",
    "# 順伝播\n",
    "output_seq = []     # 出力データを格納するリスト\n",
    "for iseq in input_seq:\n",
    "    iseq = iseq.unsqueeze(0)    # 先頭にバッチサイズの次元1を加える\n",
    "    oseq, _ = net(iseq)\n",
    "    output_seq.append(oseq.squeeze(0)) # squeezeで先頭のバッチサイズの次元1を削除してリストに追加\n",
    "\n",
    "# 出力データの確認\n",
    "for oseq in output_seq:\n",
    "    print('output sequence:', oseq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っているデータにtorch.nn.LSTＭを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: torch.Size([20, 10, 2])\n",
      "output sequence: torch.Size([20, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_len = 10\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = torch.randn(batch_size, seq_len, input_size)\n",
    "print('input sequence:', input_seq.shape)\n",
    "\n",
    "# ネットワークの定義\n",
    "net = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "\n",
    "# 順伝播\n",
    "output_seq, _ = net(input_seq)\n",
    "\n",
    "# 出力データの確認\n",
    "print('output sequence:', output_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っているデータにtorch.nn.LSTMCellを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence： torch.Size([20, 10, 2])\n",
      "output sequence: torch.Size([20, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_len = 10\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = torch.randn(batch_size, seq_len, input_size)\n",
    "print(\"input sequence: \", input_seq.size())\n",
    "\n",
    "\n",
    "# ネットワークの定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.block_a = nn.LSTMCell(input_size, hidden_size)     # LSTMブロックA\n",
    "        self.block_b = nn.LSTMCell(hidden_size, hidden_size)    # LSTMブロックB\n",
    "    \n",
    "    def forward(self, x, hx_a0, cx_a0, hx_b0, cx_b0):\n",
    "        '''\n",
    "        :param x: 現時刻の入力シーケンスの状態\n",
    "        :param hx_a0: 前時刻のLSTMブロックAの隠れ層の状態\n",
    "        :param cx_a0: 前時刻のLSTMブロックAのセル状態\n",
    "        :param hx_b0: 前時刻のLSTMブロックBの隠れ層の状態\n",
    "        :param cx_b0: 前時刻のLSTMブロックBのセル状態\n",
    "        :return: 現時刻のLSTMブロックAの隠れ層の状態とセル状態、現時刻のLSTMブロックBの隠れ層の状態とセル状態\n",
    "        '''\n",
    "        hx_a1, cx_a1 = self.block_a(x, (hx_a0, cx_a0))      # 現時刻のLSTMブロックAの隠れ層の状態とセル状態\n",
    "        hx_b1, cx_b1 = self.block_b(hx_a1, (hx_b0, cx_b0))  # 現時刻のLSTMブロックBの隠れ層の状態とセル状態\n",
    "        return hx_a1, cx_a1, hx_b1, cx_b1\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# 隠れ層の初期化\n",
    "hx_a = torch.randn(batch_size, hidden_size)\n",
    "cx_a = torch.randn(batch_size, hidden_size)\n",
    "hx_b = torch.randn(batch_size, hidden_size)\n",
    "cx_b = torch.randn(batch_size, hidden_size)\n",
    "\n",
    "# 順伝播\n",
    "output_seq = []     # 出力データを格納するリスト\n",
    "for i in range(seq_len):\n",
    "    hx_a, cx_a, hx_b, cx_b = net(input_seq[:, i, :], hx_a, cx_a, hx_b, cx_b)\n",
    "    output_seq.append(hx_b)   # リストに追加\n",
    "output_seq = torch.stack(output_seq, dim=1)     # リストからTensorに変換\n",
    "\n",
    "# 出力データの確認\n",
    "print('output sequence:', output_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多対一のリカレントニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っていないデータにtorch.nn.LSTＭを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: torch.Size([8, 2])\n",
      "input sequence: torch.Size([6, 2])\n",
      "input sequence: torch.Size([10, 2])\n",
      "output data: torch.Size([4])\n",
      "output data: torch.Size([4])\n",
      "output data: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "seq_len_list = [8, 6, 10]\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = []\n",
    "for seq_len in seq_len_list:\n",
    "    iseq = torch.randn(seq_len, input_size)\n",
    "    print('input sequence:', iseq.shape)\n",
    "    input_seq.append(iseq)\n",
    "\n",
    "# ネットワークの定義\n",
    "net = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "\n",
    "# 順伝播\n",
    "output_data = []     # 出力データを格納するリスト\n",
    "for iseq in input_seq:\n",
    "    iseq = iseq.unsqueeze(0)    # 先頭にバッチサイズの次元1を加える\n",
    "    oseq, _ = net(iseq)\n",
    "    # スライスでシーケンスの最終状態のみ取り出し、squeezeで先頭のバッチサイズの次元1を除去してリストに追加\n",
    "    output_data.append(oseq[:, -1, :].squeeze(0))\n",
    "\n",
    "# 出力データの確認\n",
    "for odata in output_data:\n",
    "    print('output data:', odata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っているデータにtorch.nn.LSTＭを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: torch.Size([20, 10, 2])\n",
      "output data: torch.Size([20, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_len = 10\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = torch.randn(batch_size, seq_len, input_size)\n",
    "print('input sequence:', input_seq.shape)\n",
    "\n",
    "# ネットワークの定義\n",
    "net = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "\n",
    "# 順伝播\n",
    "output_seq, _ = net(input_seq)\n",
    "output_data = output_seq[:, -1, :] # スライスでシーケンスの最終状態のみ使う\n",
    "\n",
    "# 出力データの確認\n",
    "print('output data:', output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シーケンス長が揃っているデータにtorch.nn.LSTＭＣｅｌｌを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence： torch.Size([20, 10, 2])\n",
      "output data: torch.Size([20, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_len = 10\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "# 入力データのサンプル\n",
    "input_seq = torch.randn(batch_size, seq_len, input_size)\n",
    "print(\"input sequence: \", input_seq.size())\n",
    "\n",
    "\n",
    "# ネットワークの定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.block_a = nn.LSTMCell(input_size, hidden_size)  # LSTMブロックA\n",
    "        self.block_b = nn.LSTMCell(hidden_size, hidden_size)  # LSTMブロックB\n",
    "\n",
    "    def forward(self, x, hx_a0, cx_a0, hx_b0, cx_b0):\n",
    "        '''\n",
    "        :param x: 現時刻の入力シーケンスの状態\n",
    "        :param hx_a0: 前時刻のLSTMブロックAの隠れ層の状態\n",
    "        :param cx_a0: 前時刻のLSTMブロックAのセル状態\n",
    "        :param hx_b0: 前時刻のLSTMブロックBの隠れ層の状態\n",
    "        :param cx_b0: 前時刻のLSTMブロックBのセル状態\n",
    "        :return: 現時刻のLSTMブロックAの隠れ層の状態とセル状態、現時刻のLSTMブロックBの隠れ層の状態とセル状態\n",
    "        '''\n",
    "        hx_a1, cx_a1 = self.block_a(x, (hx_a0, cx_a0))  # 現時刻のLSTMブロックAの隠れ層の状態とセル状態\n",
    "        hx_b1, cx_b1 = self.block_b(hx_a1, (hx_b0, cx_b0))  # 現時刻のLSTMブロックBの隠れ層の状態とセル状態\n",
    "        return hx_a1, cx_a1, hx_b1, cx_b1\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# 隠れ層の初期化\n",
    "hx_a = torch.randn(batch_size, hidden_size)\n",
    "cx_a = torch.randn(batch_size, hidden_size)\n",
    "hx_b = torch.randn(batch_size, hidden_size)\n",
    "cx_b = torch.randn(batch_size, hidden_size)\n",
    "\n",
    "# 出力データを生成\n",
    "for i in range(seq_len):\n",
    "    hx_a, cx_a, hx_b, hx_b = net(input_seq[:, i, :], hx_a, cx_a, hx_b, cx_b)\n",
    "output_data = hx_b     # シーケンスの最終状態のみ取り出し出力とする\n",
    "\n",
    "# 出力データの確認\n",
    "print('output data:', output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_handbook-cxE4JzpW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 (default, Feb 12 2023, 23:20:22) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1627ff8c3f0278be0285d4bfdc18dde91f8374edbf4a554c43de70be81795e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
