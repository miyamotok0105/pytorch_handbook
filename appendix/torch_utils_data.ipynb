{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #colabを使う方はこちらを使用ください。\n",
    "# !pip install torch==1.5.0\n",
    "# !pip install torchvision==0.6.0\n",
    "# !pip install torchtext==0.3.1\n",
    "# !pip install numpy==1.21.6\n",
    "# !pip install matplotlib==3.2.2\n",
    "# !pip install Pillow==7.1.2\n",
    "# !pip install opencv-python==4.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tensorからのデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand(400, 3)\n",
    "y1 = torch.rand(400, 1)\n",
    "dataset1 = torch.utils.data.TensorDataset(x1, y1)   # x1とy1からデータセット1を作成\n",
    "\n",
    "len(dataset1)   # データセット1のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0121, 0.9901, 0.9089]), tensor([0.3177]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0]     # データセット1の最初の行の内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#データセットの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.rand(600, 3)\n",
    "y2 = torch.rand(600, 1)\n",
    "dataset2 = torch.utils.data.TensorDataset(x2, y2)   # x2とy2からデータセット2を作成\n",
    "\n",
    "len(dataset2)   # データセット2のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = torch.utils.data.ConcatDataset([dataset1, dataset2])     # データセット1とデータセット2を結合してデータセット3を作成\n",
    "\n",
    "len(dataset3)   # データセット3のデータ数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#データセットの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices4 = [i for i in range(0, 700)]\n",
    "indices5 = [i for i in range(700, 1000)]\n",
    "dataset4 = torch.utils.data.Subset(dataset3, indices=indices4)  # データセット3の0~699行からデータセット４を作成\n",
    "dataset5 = torch.utils.data.Subset(dataset3, indices=indices5)  # データセット3の700~999行からデータセット5を作成\n",
    "\n",
    "len(dataset4)   # データセット4のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset5)   # データセット5のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0121, 0.9901, 0.9089]), tensor([0.3177]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4[0]     # データセット4の最初の行の内容（＝データセット1の最初の行の内容）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3770, 0.6534, 0.1723]), tensor([0.3817]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset5[0]     # データセット5の最初の行の内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#データセットのランダム分割（重複なし）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセット3からランダムに700行と300行のデータセットを作成\n",
    "dataset6, dataset7 = torch.utils.data.random_split(dataset3, [700, 300])\n",
    "\n",
    "len(dataset6)   # データセット6のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset7)   # データセット7のデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2703, 0.4003, 0.1655]), tensor([0.0758]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset6[0]     # データセット6の最初の行の内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5379, 0.9860, 0.6402]), tensor([0.5501]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset7[0]     # データセット7の最初の行の内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#データローダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 5      # エポックサイズの設定\n",
    "batch_size = 3      # バッチサイズの設定\n",
    "num_workers = 2     # データ読み込みに使用するサブプロセス数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセット3を8:2でトレーニングデータセットとバリデーションデータセットに分割\n",
    "train_set, valid_set = torch.utils.data.random_split(dataset3, [800, 200])\n",
    "\n",
    "len(train_set)  # トレーニングデータセットのデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_set)  # バリデーションデータセットのデータ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "epoch: 0\n",
      "########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop iteration: 0\n",
      "[tensor([[0.1969, 0.7810, 0.0705],\n",
      "        [0.9704, 0.7199, 0.1348],\n",
      "        [0.5096, 0.1675, 0.4872]]), tensor([[0.7093],\n",
      "        [0.9843],\n",
      "        [0.0582]])]\n",
      "training loop iteration: 1\n",
      "[tensor([[0.4182, 0.0102, 0.8858],\n",
      "        [0.3169, 0.8320, 0.3488],\n",
      "        [0.1726, 0.1487, 0.2476]]), tensor([[0.5464],\n",
      "        [0.4406],\n",
      "        [0.6874]])]\n",
      "training loop iteration: 2\n",
      "[tensor([[0.1649, 0.8776, 0.9455],\n",
      "        [0.5622, 0.1700, 0.8686],\n",
      "        [0.6193, 0.3062, 0.3511]]), tensor([[0.7984],\n",
      "        [0.6096],\n",
      "        [0.9278]])]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loop iteration: 0\n",
      "[tensor([[0.8678, 0.6692, 0.7742],\n",
      "        [0.6371, 0.1026, 0.2763],\n",
      "        [0.8830, 0.0627, 0.6976]]), tensor([[0.0817],\n",
      "        [0.2908],\n",
      "        [0.6758]])]\n",
      "validation loop iteration: 1\n",
      "[tensor([[0.7379, 0.2987, 0.1475],\n",
      "        [0.4695, 0.0018, 0.5387],\n",
      "        [0.4746, 0.5025, 0.8335]]), tensor([[0.5897],\n",
      "        [0.1859],\n",
      "        [0.6020]])]\n",
      "validation loop iteration: 2\n",
      "[tensor([[0.6407, 0.0993, 0.2433],\n",
      "        [0.9272, 0.9445, 0.1853],\n",
      "        [0.9318, 0.7057, 0.7579]]), tensor([[0.2345],\n",
      "        [0.2901],\n",
      "        [0.6494]])]\n",
      "\n",
      "########\n",
      "epoch: 1\n",
      "########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop iteration: 0\n",
      "[tensor([[0.3303, 0.1698, 0.7258],\n",
      "        [0.9608, 0.4488, 0.1188],\n",
      "        [0.6757, 0.7736, 0.7145]]), tensor([[0.6004],\n",
      "        [0.6274],\n",
      "        [0.5815]])]\n",
      "training loop iteration: 1\n",
      "[tensor([[0.0452, 0.9374, 0.1921],\n",
      "        [0.8132, 0.4905, 0.0013],\n",
      "        [0.9806, 0.5789, 0.4964]]), tensor([[0.2065],\n",
      "        [0.6103],\n",
      "        [0.1807]])]\n",
      "training loop iteration: 2\n",
      "[tensor([[0.9075, 0.6534, 0.8947],\n",
      "        [0.2553, 0.7156, 0.4117],\n",
      "        [0.3778, 0.5835, 0.4972]]), tensor([[0.8572],\n",
      "        [0.7496],\n",
      "        [0.0353]])]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loop iteration: 0\n",
      "[tensor([[0.8678, 0.6692, 0.7742],\n",
      "        [0.6371, 0.1026, 0.2763],\n",
      "        [0.8830, 0.0627, 0.6976]]), tensor([[0.0817],\n",
      "        [0.2908],\n",
      "        [0.6758]])]\n",
      "validation loop iteration: 1\n",
      "[tensor([[0.7379, 0.2987, 0.1475],\n",
      "        [0.4695, 0.0018, 0.5387],\n",
      "        [0.4746, 0.5025, 0.8335]]), tensor([[0.5897],\n",
      "        [0.1859],\n",
      "        [0.6020]])]\n",
      "validation loop iteration: 2\n",
      "[tensor([[0.6407, 0.0993, 0.2433],\n",
      "        [0.9272, 0.9445, 0.1853],\n",
      "        [0.9318, 0.7057, 0.7579]]), tensor([[0.2345],\n",
      "        [0.2901],\n",
      "        [0.6494]])]\n",
      "\n",
      "########\n",
      "epoch: 2\n",
      "########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop iteration: 0\n",
      "[tensor([[0.9055, 0.4033, 0.0192],\n",
      "        [0.9920, 0.6897, 0.4617],\n",
      "        [0.0464, 0.3264, 0.6852]]), tensor([[0.3786],\n",
      "        [0.5298],\n",
      "        [0.4584]])]\n",
      "training loop iteration: 1\n",
      "[tensor([[0.7934, 0.4755, 0.5183],\n",
      "        [0.0075, 0.4875, 0.0383],\n",
      "        [0.6240, 0.3376, 0.2103]]), tensor([[0.1064],\n",
      "        [0.3516],\n",
      "        [0.6366]])]\n",
      "training loop iteration: 2\n",
      "[tensor([[0.8595, 0.9278, 0.9775],\n",
      "        [0.1380, 0.3967, 0.5815],\n",
      "        [0.0890, 0.0371, 0.8678]]), tensor([[0.1333],\n",
      "        [0.2560],\n",
      "        [0.3765]])]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loop iteration: 0\n",
      "[tensor([[0.8678, 0.6692, 0.7742],\n",
      "        [0.6371, 0.1026, 0.2763],\n",
      "        [0.8830, 0.0627, 0.6976]]), tensor([[0.0817],\n",
      "        [0.2908],\n",
      "        [0.6758]])]\n",
      "validation loop iteration: 1\n",
      "[tensor([[0.7379, 0.2987, 0.1475],\n",
      "        [0.4695, 0.0018, 0.5387],\n",
      "        [0.4746, 0.5025, 0.8335]]), tensor([[0.5897],\n",
      "        [0.1859],\n",
      "        [0.6020]])]\n",
      "validation loop iteration: 2\n",
      "[tensor([[0.6407, 0.0993, 0.2433],\n",
      "        [0.9272, 0.9445, 0.1853],\n",
      "        [0.9318, 0.7057, 0.7579]]), tensor([[0.2345],\n",
      "        [0.2901],\n",
      "        [0.6494]])]\n",
      "\n",
      "########\n",
      "epoch: 3\n",
      "########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop iteration: 0\n",
      "[tensor([[0.1677, 0.3746, 0.9544],\n",
      "        [0.6232, 0.2552, 0.8245],\n",
      "        [0.6610, 0.4539, 0.4255]]), tensor([[0.1919],\n",
      "        [0.3966],\n",
      "        [0.4432]])]\n",
      "training loop iteration: 1\n",
      "[tensor([[0.7062, 0.7595, 0.8360],\n",
      "        [0.1615, 0.0979, 0.3788],\n",
      "        [0.3457, 0.2451, 0.8684]]), tensor([[0.5175],\n",
      "        [0.8472],\n",
      "        [0.2703]])]\n",
      "training loop iteration: 2\n",
      "[tensor([[0.6335, 0.2168, 0.6544],\n",
      "        [0.5880, 0.6971, 0.9894],\n",
      "        [0.1649, 0.8776, 0.9455]]), tensor([[0.1952],\n",
      "        [0.9936],\n",
      "        [0.7984]])]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loop iteration: 0\n",
      "[tensor([[0.8678, 0.6692, 0.7742],\n",
      "        [0.6371, 0.1026, 0.2763],\n",
      "        [0.8830, 0.0627, 0.6976]]), tensor([[0.0817],\n",
      "        [0.2908],\n",
      "        [0.6758]])]\n",
      "validation loop iteration: 1\n",
      "[tensor([[0.7379, 0.2987, 0.1475],\n",
      "        [0.4695, 0.0018, 0.5387],\n",
      "        [0.4746, 0.5025, 0.8335]]), tensor([[0.5897],\n",
      "        [0.1859],\n",
      "        [0.6020]])]\n",
      "validation loop iteration: 2\n",
      "[tensor([[0.6407, 0.0993, 0.2433],\n",
      "        [0.9272, 0.9445, 0.1853],\n",
      "        [0.9318, 0.7057, 0.7579]]), tensor([[0.2345],\n",
      "        [0.2901],\n",
      "        [0.6494]])]\n",
      "\n",
      "########\n",
      "epoch: 4\n",
      "########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop iteration: 0\n",
      "[tensor([[0.1752, 0.8813, 0.0413],\n",
      "        [0.1629, 0.1804, 0.7786],\n",
      "        [0.9595, 0.7946, 0.1695]]), tensor([[0.8211],\n",
      "        [0.6245],\n",
      "        [0.8714]])]\n",
      "training loop iteration: 1\n",
      "[tensor([[0.3303, 0.1698, 0.7258],\n",
      "        [0.6826, 0.4501, 0.6100],\n",
      "        [0.4809, 0.7765, 0.8901]]), tensor([[0.6004],\n",
      "        [0.1192],\n",
      "        [0.3797]])]\n",
      "training loop iteration: 2\n",
      "[tensor([[0.9678, 0.0594, 0.8241],\n",
      "        [0.6858, 0.3087, 0.7685],\n",
      "        [0.3958, 0.2562, 0.9763]]), tensor([[0.1304],\n",
      "        [0.2343],\n",
      "        [0.2368]])]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loop iteration: 0\n",
      "[tensor([[0.8678, 0.6692, 0.7742],\n",
      "        [0.6371, 0.1026, 0.2763],\n",
      "        [0.8830, 0.0627, 0.6976]]), tensor([[0.0817],\n",
      "        [0.2908],\n",
      "        [0.6758]])]\n",
      "validation loop iteration: 1\n",
      "[tensor([[0.7379, 0.2987, 0.1475],\n",
      "        [0.4695, 0.0018, 0.5387],\n",
      "        [0.4746, 0.5025, 0.8335]]), tensor([[0.5897],\n",
      "        [0.1859],\n",
      "        [0.6020]])]\n",
      "validation loop iteration: 2\n",
      "[tensor([[0.6407, 0.0993, 0.2433],\n",
      "        [0.9272, 0.9445, 0.1853],\n",
      "        [0.9318, 0.7057, 0.7579]]), tensor([[0.2345],\n",
      "        [0.2901],\n",
      "        [0.6494]])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# トレーニングデータセットのデータローダー（シャッフルON）\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# バリデーションデータセットのデータローダー（シャッフルOFF）\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "for epoch in range(epoch_size):     # 学習ループ\n",
    "    print('########')\n",
    "    print('epoch:', epoch)\n",
    "    print('########')\n",
    "\n",
    "    for itr, data in enumerate(train_loader):   # トレーニングのループ\n",
    "        print('training loop iteration:', itr)\n",
    "        print(data)     # シャッフルONなのでエポックごとに異なる\n",
    "        if itr >= 2:\n",
    "            break\n",
    "    print()\n",
    "\n",
    "    for itr, data in enumerate(valid_loader):   # バリデーションのループ\n",
    "        print('validation loop iteration:', itr)\n",
    "        print(data)     # シャッフルOFFなのでエポックが変わっても同一\n",
    "        if itr >= 2:\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_handbook-cxE4JzpW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.13 (default, Feb 12 2023, 23:20:22) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1627ff8c3f0278be0285d4bfdc18dde91f8374edbf4a554c43de70be81795e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
